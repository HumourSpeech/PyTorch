{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f8dfad",
   "metadata": {},
   "source": [
    "<H4>What is dataloader</H4>\n",
    "\n",
    "- It takes a dataset.\n",
    "- Creates batches\n",
    "- Shuffles data\n",
    "- Loads data efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff44969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "        self.y = torch.tensor([2, 4, 6, 8, 10], dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f126985",
   "metadata": {},
   "source": [
    "<h3> Creating Data Loader </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ea04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataset = SimpleDataset()\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a44c82",
   "metadata": {},
   "source": [
    "Now the Data is shuffled and grouped into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffac2fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 4.]) tensor([2., 8.])\n",
      "tensor([2., 5.]) tensor([ 4., 10.])\n",
      "tensor([3.]) tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "for batchX, batchY in loader:\n",
    "    print(batchX, batchY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf24804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.],\n",
      "        [4.]])\n",
      "tensor([[10.],\n",
      "        [ 8.]])\n",
      "tensor([[1.],\n",
      "        [3.]])\n",
      "tensor([[2.],\n",
      "        [6.]])\n",
      "tensor([[2.]])\n",
      "tensor([[4.]])\n"
     ]
    }
   ],
   "source": [
    "for batchX, batchY in loader:\n",
    "    print(batchX.view(-1, 1))\n",
    "    print(batchY.view(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee6b12",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f93fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(1, 1)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df64d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss 35.20134353637695\n",
      "Epoch 1: Loss 1.348494052886963\n",
      "Epoch 2: Loss 0.2828003764152527\n",
      "Epoch 3: Loss 0.09064068645238876\n",
      "Epoch 4: Loss 0.1604979932308197\n",
      "Epoch 5: Loss 0.017627129331231117\n",
      "Epoch 6: Loss 0.043362122029066086\n",
      "Epoch 7: Loss 0.05831851810216904\n",
      "Epoch 8: Loss 0.008720354177057743\n",
      "Epoch 9: Loss 0.12110701948404312\n",
      "Epoch 10: Loss 0.04412495344877243\n",
      "Epoch 11: Loss 0.11093009263277054\n",
      "Epoch 12: Loss 0.04143565148115158\n",
      "Epoch 13: Loss 0.03907747566699982\n",
      "Epoch 14: Loss 0.006892671808600426\n",
      "Epoch 15: Loss 0.042529404163360596\n",
      "Epoch 16: Loss 0.005525493994355202\n",
      "Epoch 17: Loss 0.038001082837581635\n",
      "Epoch 18: Loss 0.03674193471670151\n",
      "Epoch 19: Loss 0.005699891597032547\n",
      "Epoch 20: Loss 0.03603934496641159\n",
      "Epoch 21: Loss 0.09115283936262131\n",
      "Epoch 22: Loss 0.04793546348810196\n",
      "Epoch 23: Loss 0.04273330420255661\n",
      "Epoch 24: Loss 0.005918231792747974\n",
      "Epoch 25: Loss 0.0844867154955864\n",
      "Epoch 26: Loss 0.003599134972319007\n",
      "Epoch 27: Loss 0.08022372424602509\n",
      "Epoch 28: Loss 0.07832209765911102\n",
      "Epoch 29: Loss 0.004066042136400938\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "\n",
    "    for batchX, batchY in loader:\n",
    "        batchX = batchX.view(-1, 1)\n",
    "        batchY = batchY.view(-1, 1)\n",
    "\n",
    "        y_pred = model(batchX)\n",
    "        loss = criterion(y_pred, batchY)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch}: Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266f455a",
   "metadata": {},
   "source": [
    "<h4>Notes</h4>\n",
    "\n",
    "Dataset defines how to access individual data samples, while DataLoader handles batching and shuffling for efficient training.\n",
    "\n",
    "Dataset gives ONE sample.\n",
    "\n",
    "DataLoader gives MANY samples (batch).\n",
    "\n",
    "Training loop iterates over batches.\n",
    "\n",
    "Epoch = one full pass over dataset.\n",
    "\n",
    "Shuffle changes order every epoch.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
